# 共轭梯度法和预优共轭梯度法

## 共轭梯度法

```matlab
function [x, step] = conjugate_gradient(x0, A, b, epsilon)
% Use conjugate gradient method to solve linear system Ax = b.
%
% Arguments
% ---------
% x0      : initial value
% A, b    : Ax = b
% epsilon : scalar, a float number very close to 0, say 1e-7
%
% Returns
% -------
% x      : the answer for Ax = b
% step   : scalar, number of steps to reach x.

if nargin == 3
    epsilon = 1e-7;
end

x = x0;
r0 = 0;
r1 = 0;
p = 0;
step = 0;
while true
    step = step + 1;
    [x, r1, r0, p] = move_one_step(x, A, b, r1, r0, p, step==1);
    if r1' * r1 < epsilon
        break
    end
end


function [xnext, rnext, r, p] = move_one_step(x, A, b, r, rprev, pprev, first)
if first
    r = b - A*x;
    p = r;
else
    beta = (r' * r) / (rprev' * rprev);
    p = r + beta.*pprev;
end
t = A * p;
alpha = (r' * p) / (p' * t);
xnext = x + alpha.*p;
rnext = r - alpha.*t;
```

## 预优共轭梯度法

```matlab
function [x, k] = pre_conjugate_gradient(x0, A, b, M, epsilon);
% Preconditioned conjugate gradient method
%
% Arguments
% ---------
% x0       : initial value
% A, b     : Ax = b
% M        : preconditioned matrix
% epsilon  : scalar, a float number very close to 0.0, say 1e-7
%
% Returns
% -------
% x     : the answer for Ax = b
% k     : scalar, number of steps to reach x

if nargin == 4
    epsilon = 1e-7;
end

x = x0;
r = 0;
z = 0;
p = 0;
rou = 0;
k = 0;
while true
	k = k + 1;
	[x, r, z, p, rou] = move_one_step(x, A, b, M, r, z, p, rou, k == 1);
	if r' * r < epsilon
		break
	end
end


function [xnext, rnext, znext, pnext, rounext] = move_one_step(x, A, b, M, r, z, p, rou, first)
if first
	r = b - A*x;
	z = M \ r;
	rou = r'*z;
	p = z;
end
w = A * p;
alpha = rou / (p'*w);
xnext = x + alpha * p;
rnext = r - alpha * w;
znext = M \ rnext;
rounext = rnext' * znext;
beta = rounext / rou;
pnext = znext + beta * p;
```

## 实验设置

为了比较预优共轭梯度法的优越性，设计如下带状矩阵：
$$
A = \begin{bmatrix}
2 & 3 & 0 & 0 & \cdots & 0\\
3 & 2 & 3 & 0& \cdots & 0\\
0 & 3 & 2 & 3 & \cdots & 0 \\
0 & 0 & 3 & 2 &\cdots & 0 \\
\vdots & \vdots & \vdots & \vdots &\ddots &\vdots\\
0 & 0 & 0 & 0 & \cdots & 2
\end{bmatrix}\\
$$
另外，对矩阵$A$的对角线元素随机加上0, 100或-100，$b = [1, 1, 1, \cdots, 1]^T$。下面对$A$的不同维度做探究，

![](images/ex03-1.png)

误差$e$定义如下：
$$
e = \max_{1\le i \le n}\frac{|x_i - xt_i|}{\max(|x_i|+|xt_i|, 1e^{-8})}
$$
其中$xt$为用matlab语言的内置左除计算结果`xt = A \ b`，而$x$为迭代算法的输出结果。

## 具体结果

这里取维度$n=5$的矩阵$A$，$b = [1, 1, 1, 1, 1]^T$分别使用`xt = A \ b`， 共轭梯度法和预优共轭梯度法的结果。

```matlab
xt   = [ -0.0217 -0.3478 -0.5435 -0.3478 -0.0217] % xt = A \ b
xgd  = [ -0.0217 -0.3478 -0.5435 -0.3478 -0.0217] % conjugate gradient
xpgd = [ -0.0217 -0.3478 -0.5435 -0.3478 -0.0217] % preconditioned conjugate gradient
```



